#pip install pandas supabase scikit-learn
#pip install torch --index-url https://download.pytorch.org/whl/cpu
#pip install numpy==1.24.3
#pip install scipy==1.10.1

import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
from supabase import create_client
from datetime import timedelta, datetime, date
from sklearn.preprocessing import MinMaxScaler

# --- 1. Supabase ì—°ê²° ---
url = "https://vcqqokmyyjsvxyvuzgmv.supabase.co"
key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZjcXFva215eWpzdnh5dnV6Z212Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjA5MjE2OTgsImV4cCI6MjA3NjQ5NzY5OH0.lv0mtev8N61_QicEObv5Bdbk7Gpwnh-tLnkX0M-SI5Q"
supabase = create_client(url, key)

# --- 2. ê³¼ê±° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ---
past_resp = supabase.table("r_weather_data").select("*").execute()
past_data = pd.DataFrame(past_resp.data)

# --- 3. ì „ì²˜ë¦¬ ---
past_data['datetime'] = pd.to_datetime(past_data['r_timestamp'])
past_data['r_insolation'] = past_data['r_insolation'].replace(-9, 0)
past_data = past_data.rename(columns={'r_insolation': 'target'})
past_data = past_data.dropna(subset=['target'])

# --- 4. í•¨ìˆ˜ ì •ì˜ ---
def get_time_window_avg(df, current_time, window_hours=2):
    """current_time ê¸°ì¤€ Â±window_hours ì‹œê°„ ë²”ìœ„ ë‚´ target í‰ê·  ë°˜í™˜"""
    start = current_time - timedelta(hours=window_hours)
    end = current_time + timedelta(hours=window_hours)
    window_data = df[(df['datetime'] >= start) & (df['datetime'] <= end)]
    if window_data.empty:
        return None
    return window_data['target'].mean()

def create_custom_sequence(df, pred_time, seq_length=13, intervals=[24,48,72], window_hours=2):
    """pred_time ê¸°ì¤€ìœ¼ë¡œ intervals ì‹œê°„ë§Œí¼ ê³¼ê±° Â±window_hours êµ¬ê°„ í‰ê· ê°’ìœ¼ë¡œ ì‹œí€€ìŠ¤ ìƒì„±"""
    seq = []
    for hours_ago in intervals:
        base_time = pred_time - timedelta(hours=hours_ago)
        val = get_time_window_avg(df, base_time, window_hours)
        if val is None:
            val = 0.0
        seq.append(val)
    seq = (seq * (seq_length // len(seq) + 1))[:seq_length]
    return np.array(seq)

def create_training_data(df, seq_length=13, intervals=[24,48,72], window_hours=2):
    X, y, times = [], [], []
    df = df.sort_values('datetime').reset_index(drop=True)
    for idx in range(seq_length, len(df)):
        pred_time = df.loc[idx, 'datetime']
        seq = create_custom_sequence(df, pred_time, seq_length, intervals, window_hours)
        target = df.loc[idx, 'target']
        X.append(seq)
        y.append(target)
        times.append(pred_time)
    return np.array(X), np.array(y), times

# --- 5. í•™ìŠµ ë°ì´í„° ìƒì„± ---
X_train, y_train, train_times = create_training_data(past_data)
X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)
y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)

# --- 6. LSTM ëª¨ë¸ ì •ì˜ ---
class LSTMModel(nn.Module):
    def __init__(self, input_size=1, hidden_size=64, num_layers=1):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.linear = nn.Linear(hidden_size, 1)
    def forward(self, x):
        out, _ = self.lstm(x)
        out = out[:, -1, :]
        out = self.linear(out)
        return out

model = LSTMModel()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# --- 7. ëª¨ë¸ í•™ìŠµ ---
epochs = 50
for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()
    if (epoch + 1) % 10 == 0 or epoch == 0:
        print(f"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}")

# --- 8. 24ì‹œê°„ ì˜ˆì¸¡ ---
model.eval()
predictions = []
with torch.no_grad():
    last_time = past_data['datetime'].max().replace(minute=0, second=0, microsecond=0)
    for hour in range(24):
        pred_time = last_time.replace(hour=hour)
        seq = create_custom_sequence(past_data, pred_time, seq_length=13)
        x_input = torch.tensor(seq, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)
        pred = model(x_input).item()
        pred = max(pred, 0)
        if pred_time.hour < 6 or pred_time.hour > 18:
            pred = 0.0
        predictions.append((pred_time, pred))

# --- 9. ì „ë ¥ ì†Œë¹„ ê³„ì‚° ---
def calculate_power(irradiance_pred):
    max_irradiance = 1000
    base_power = 1.0
    led_power = 5 * 0.2
    rgb_power = 4 * 0.05
    servo_power = 2 * 0.1
    sensor_power = 0.3
    power = base_power + led_power * (irradiance_pred / max_irradiance) + rgb_power + servo_power + sensor_power
    return power


# --- 10. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆ ë°ì´í„° ì—…ë¡œë“œ ---
records = []
for pred_time, val in predictions:
    power = calculate_power(val)
    record = {
        "predicted_time": pred_time.isoformat(),
        "pred_insolation": float(val),
        "pred_power": float(power),
        "timestamp": pd.Timestamp.now().isoformat()
    }
    records.append(record)

try:
    # ê¸°ì¡´ ëª¨ë“  prediction ë°ì´í„° ì‚­ì œ
    supabase.frome_("prediction").delete().execute()
    
    print("ğŸ—‘ï¸ ê¸°ì¡´ prediction í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„° ì‚­ì œ ì™„ë£Œ")

    # ìƒˆ ë°ì´í„° ì‚½ì…
    response = supabase.table("prediction").insert(records).execute()
    print(f"\nâœ… Supabase ì—…ë¡œë“œ ì™„ë£Œ: {len(records)}ê°œì˜ ì˜ˆì¸¡ê°’ ì €ì¥ë¨")

except Exception as e:
    print("âŒ Supabase ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)



# --- 11. ì½˜ì†” ì¶œë ¥ ---
print("\nì˜ˆì¸¡ëœ 24ì‹œê°„ ì¼ì‚¬ëŸ‰ ë° ì „ë ¥ ì†Œë¹„ëŸ‰:")
for pred_time, val in predictions:
    power = calculate_power(val)
    print(f"{pred_time.strftime('%Y-%m-%d %H:%M')} â†’ ì¼ì‚¬ëŸ‰ {val:.3f} W/mÂ² | ì†Œë¹„ì „ë ¥ {power:.3f} W")

print("\nâœ… ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
